{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.1 리플 데이터 NLP\n",
    "> 목적 : 키워드별 리플 csv파일을 이용해 각 월별 빈도수를 xlsx로 export한다.   \n",
    "    \n",
    "\n",
    "> * 추가 task 1.    )   \n",
    ": 수집된 전체 리플 중에 '국민'이 들어간 리플만 뽑아내어 csv 편성하기  \n",
    "\n",
    "\n",
    "> 작업 : \"\" pos태깅 + 클렌징 \"\"   \n",
    "=> task1).  Konlpy를 써서 pos태깅 > '조사','어미','문장부호'등을 drop하기\n",
    "=> task2).너무 쪼개어진 단어 붙여주기 > 예) '김''무성' > '김무성'    \n",
    "=> task3).숫자, 한 음절 drop하기     \n",
    "=> task4).불용어(stopwords) 설정하기      \n",
    "=> task5).최빈단어순으로 정리된 데이터프레임을 csv파일로 export하기    \n",
    "=> task6).최빈단어 랭크에 들지 못해도 꼭 넣어주어야하는 특정단어 지정하여 최빈 단어 데이터 프레임에 넣어주기   \n",
    "=>     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> * 추가 task 2)   \n",
    "concordance 체크 :     \n",
    "nltk.text.concordance('원하는 단어') 명령을 통해서, 원하는 단어가 수집한 리플들 가운데 어떻게 쓰이고 있는지를 확인할 수 있게 해줍니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### * 필요 패키지 import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime  # < 'datetime' 데이터 형태를 조작하기 편하도록 해줍니다. * 참고 pandas.datetime\n",
    "\n",
    "import platform\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re     #파이썬에서 정규표현식(Regular Expression) 지원 모듈\n",
    "\n",
    "%matplotlib inline \n",
    "# < matpliotlib 을 주피터 노트북에서 사용할 경우 plot들을 결과 창 안에 맞춰 출력시켜주도록 해줍니다. \n",
    "# 설정하지 않아도 크게 문제가 되지는 않지만, matpliot을 쓸 때 custumary하게 주로 지정해주고 시작합니다. \n",
    "\n",
    "# matplot 한글 폰트 인식 코드 \n",
    "# matpliot 자체에서는 한글폰트를 자동으로 인식하지 못합니다. \n",
    "# matpliot의 plotting paremeter에서 직접 한글폰트 경로를 넣어주면 plot에 한글 출력이 가능해집니다. \n",
    "path = \"c:/Windows/Fonts/malgun.ttf\" # < 윈도우에 '맑은 고딕' 폰트의 경로입니다.\n",
    "from matplotlib import font_manager, rc\n",
    "if platform.system() == 'Darwin':  # < 맥킨토시 사용자의 경우 \n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows': # < 윈도우 사용자의 경우 \n",
    "    font_name = font_manager.FontProperties(fname=path).get_name() \n",
    "    rc('font', family=font_name)\n",
    "    # 사용하고자 하는 한글 폰트의 경로를 path에 지정해주세요.\n",
    "else:\n",
    "    print('Unknown OS')    \n",
    "\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* nltk (Natural Language Toolkit) < 기본적인 자연어 처리 작업을 도와주는 패키지입니다.    \n",
    "=> 한글에 맞춰진 패키지가 아니기 때문에, 한글 NLP 과정에는 '토크나이즈' 작업을 nltk로 할 수 없지만     \n",
    "'최빈 단어','연어(collocation)','단어 색인(concordance)','산포도 그림(dispersion_plot)'등을 쓰기 좋습니다. \n",
    "(참고: https://datascienceschool.net/view-notebook/8895b16a141749a9bb381007d52721c1/)\n",
    "(참고: (nltk class 공식페이지) :https://www.nltk.org/_modules/nltk/text.html)\n",
    "\n",
    "* Konlpy (Python package for Korean natural language processing)    \n",
    "(코엔엘파이 공식 페이지 : https://konlpy-ko.readthedocs.io/ko/v0.4.3/)   \n",
    "한국어 자연어 정보처리를 위한 패키지입니다. 한글 문법에 따라 형태소 분해, 토크나이징을 수행할 수 있게 해줍니다. Konlpy 안에 Hannanum Class(한나눔), Kkma Class(꼬꼬마), Komoran Class(코모란), Mecab Class(미캅), Twitter Class(트위터) 클래스들이 존재합니다.   \n",
    "( 참고 : https://datascienceschool.net/view-notebook/a0237ff8f13a454c96072f868c01bc30/)   \n",
    "\n",
    "각각의 클래스들은 '자연어'를 받아서 국어 문법에 맞게 분해하는 기준이 조금씩 다르고, 그에 따라 처리속도의 차이,  pos태깅 차이(pos : part of speech, 품사) 등이 장단점이 각각 다릅니다.    \n",
    "( 클래스 간 차이 참고 : https://konlpy-ko.readthedocs.io/ko/v0.4.3/morph/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\seoun\\Anaconda3\\lib\\site-packages\\jpype\\_core.py:210: UserWarning: \n",
      "-------------------------------------------------------------------------------\n",
      "Deprecated: convertStrings was not specified when starting the JVM. The default\n",
      "behavior in JPype will be False starting in JPype 0.8. The recommended setting\n",
      "for new code is convertStrings=False.  The legacy value of True was assumed for\n",
      "this session. If you are a user of an application that reported this warning,\n",
      "please file a ticket with the developer.\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "\n",
    "from konlpy.tag import Okt # < twitter 클래스가 Okt로 이름이 바뀌었습니다.\n",
    "#Twitter 로 사용은 아직 가능하나 (deprecated) 예정입니다. \n",
    "okt = Okt()\n",
    "\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from PIL import Image\n",
    "\n",
    "from wordcloud import ImageColorGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 언론3사 + 전체기간 + 공천.csv import 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = pd.read_csv('../리플통합/공천_모든리플.csv', engine='python', header=0, index_col = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "total['rp_date'] = total.rp_date.astype('str') # < csv를 불러오면, 날짜의 dtype을 소수(float)로 인식해서 \n",
    "# '2019.10' 값이 > 2019.1 로 바뀌어 버리는 문제가 있습니다. \n",
    "# 그래서 날짜열을 다시 문자(string)로 바꾼 후에 \n",
    "total.loc[total['rp_date'] == '2019.1', 'rp_date'] = '2019.10'  # < 2019.1값을 '2019.10'으로 다시 바꿔줍니다. \n",
    "\n",
    "# 리플 항목에 NaN 이 되어 있는 경우, pos태깅에 에러가 발생합니다. \n",
    "# 따라서 결측값은 '띄어쓰기',혹은 '(아무것도 없는 칸)' 으로 만들어줍니다. \n",
    "total.fillna(' ',inplace = True)\n",
    "total.reset_index(drop = True, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['2016.01', '2016.02', '2016.03', '2019.10', '2019.11', '2019.12']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 공천 키워드에 담긴 댓글들의 날짜를 확인합니다. \n",
    "every_months = total['rp_date'].unique().tolist()\n",
    "every_months\n",
    "# 이 월별 값을 for 반복문으로 돌려\n",
    "# 월별 최빈 단어 50개를 우선 csv파일로 export하는게 목적입니다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 공천 _ 빈도 _ 월별.xlsx 제작"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### * 필터링 변수 설정 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = ['하다', '다', '들', '이', '안', 'ㅋㅋ','것', '적','ㅎㅎ','40%','대다', # << stop_words 1차 : \n",
    "                  'ㅋㅋㅋ', '그', '거', '이다', '더', '수', '건', '지', '내', '요', 'ㅋ', '한', '이번',\n",
    "                  '임', '저', '하', '근데', '다른', '결국', '제', '겠다', '어디', '나', '지다', '석', '공', '뿐',\n",
    "                  '게', '답', '때문', '웃기', '먼저', 'ㄷㄷㄷ', '성', '원래', '쪽', '이면', '뭐', '또', '올', '그게',\n",
    "                  '저런', '3', '대', '위해', '반', '가장', '그렇게', '비', '질', '그래서', '보', '날', '누구', '상',\n",
    "                  '보다','되다', '있다', '없다', '아니다', '같다', # << stop_words 2차 : 서술어\n",
    "                  '들다', '그렇다','안되다','않다','가다','못','나오다',\n",
    "                  \"관리자\", \"삭제하였습니\", \"○○○\", \"너희들\", \"하는건\", \"추한인간떨어져서\", \n",
    "                  \"안봤으면\",\"이야기\",\"정부용비어천가\",\n",
    "                  '받다', '많다', '시키다', '보내다', '되어다', '들이다', '이제', '버리다', '만들다', '살다', \n",
    "                  '차다', '쓰다', '맞다', '말다', '자기', '하의', '그리고', '당신', '이제', '나다',\n",
    "                  '하나', '너무', '이렇다', '넘다' ] # << 불용어 3차\n",
    "# 불용어에는 다시 넣어다 뺐다 핼 필요가 없을 정도로 불필요한 토큰만 넣어준다. \n",
    "# 백업용 빈도 csv에 많은 토큰을 넣어서 export하고 >\n",
    "# 시각화 단계에서 쓸/안 쓸 단어 2차 필터링 가능하니까 \n",
    "\n",
    "# 꼭 포함해주어야 하는 필수 단어를 이 안에 넣는다!\n",
    "necessary_words=['동물','짐승','문희상','아들','세습','논란','불출마','황교안','친황','청와대','문재인',\n",
    "                 '식물','배신', '배제']\n",
    "\n",
    "# 빈도가 높은 단어 '몇 등' 까지 보관할지 정해줍니다.\n",
    "freq_rank_upto = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 task 1.\n",
    "* '핵심단어'가 들어있는 리플에 대해서만 새로 csv를 뽑고자 할 때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_keyword = '공천'\n",
    "core1_keyword = '국민' # 추가 task 1) : 리플안에 '국민'이 들어간 경우 따로 빼어 새 csv에 보냅니다. \n",
    "\n",
    "word_Yes_idx = [] # < '국민'이 있는 리플의 index번호를 담을 리스트\n",
    "\n",
    "total_lines = total['rp_text']\n",
    "\n",
    "total_lines = list(map(lambda x : str(x).replace('\\r','').replace('\\n','').replace('@','').replace('*','') , total_lines))   \n",
    "\n",
    "print('3사 댓글 갯수 : ',len(total_lines))\n",
    "\n",
    "# 1차 분류를 넣을 리스트\n",
    "results = []\n",
    "lines = total_lines\n",
    "# 돌아가지 않은 리스트를 넣을 리스트\n",
    "error_lines = []\n",
    "line_idx = 0\n",
    "for line in lines: # 리플 한 줄씩 내용을 받아서\n",
    "    try:\n",
    "        malist = okt.morphs(line) # 매 문장 마다 각 형태소 분해\n",
    "        if core1_keyword in malist:\n",
    "            word_core1_idx.append(line_idx)\n",
    "    except:\n",
    "        error_lines.append(line)\n",
    "    line_idx += 1\n",
    "    if (line_idx % 10000) ==0 :\n",
    "        print(str(line_idx),'번째 라인')\n",
    "        \n",
    "file_name_core1 = '../' + Target_keyword + '_+' + core1_keyword + '_리플.csv'\n",
    "\n",
    "save_df_all = total.loc[word_Yes_idx,]\n",
    "save_df_all.reset_index(drop = True, inplace = True)\n",
    "save_df_all.to_csv(file_name_core1, encoding = 'EUC-KR', index = False)\n",
    "print('고유 댓글 총 : ',len(total),'개 중에')\n",
    "print('리플에 ' ,core1_keyword, ' 이 등장한 댓글 수 :', len(save_df_all), '개')\n",
    "print(file_name_core1, '  --->  저장 완료')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 리플 데이터 NLP 작업 수행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "공천 2016.01  빈도 분석 수행\n",
      "\n",
      "3사 댓글 갯수 :  4162\n",
      "===== 1차 Tokenization 수행 시작 =====\n",
      "리플 수 = > 라인 수 :  4162\n",
      "4000 번째 라인 pos 필터링\n",
      "에러 라인 수:  0\n",
      "조사, 어미, 문장부호 제거 후\n",
      "리플 라인 예 =>  두당이 열심히 노력해서 빛나는 은메달 많이 따시기 바랍니다. ㅎㅎ  ===> pos 필터링 결과 예 => 두 당 열심히 노력 하다 빛나다 은메달 많이 따다 바라다 ㅎㅎ\n",
      "pos 필터링 결과     =====> <Text>객체화 합니다..\n",
      "pos 필터링 결과 예 :  두 당 열심히 노력 하다 빛나다 은메달 많이 따다 바라다 ㅎㅎ  ====> WholeText[0:20]... :  두 당 열심히 노력 하다 빛나다 은메\n",
      "pos tagging 수행 =====>\n",
      "1. 토큰화 :  토큰 갯수 =====> 121361\n",
      "토큰 예시 : first_tokens[:10]... =>  ['두', '당', '열심히', '노력', '하다', '빛나다', '은메달', '많이', '따다', '바라다']\n",
      "2. 클렌징 수행, 1. 해부된 단어 재결합 + 한 글자, 숫자 filtering-out\n",
      "10000 번째 라인 재결합 작업\n",
      "20000 번째 라인 재결합 작업\n",
      "30000 번째 라인 재결합 작업\n",
      "40000 번째 라인 재결합 작업\n",
      "50000 번째 라인 재결합 작업\n",
      "60000 번째 라인 재결합 작업\n",
      "70000 번째 라인 재결합 작업\n",
      "80000 번째 라인 재결합 작업\n",
      "90000 번째 라인 재결합 작업\n",
      "100000 번째 라인 재결합 작업\n",
      "110000 번째 라인 재결합 작업\n",
      "120000 번째 라인 재결합 작업\n",
      "클렌징 후 토큰 수 :  92883\n",
      "3.  stopwords 제거\n",
      "3차 Tokens 갯수 : 73323\n",
      "1차 선별된 상위 토큰 : ['국민', '정치', '사람', '김무성', '대통령', '안철수', '대표', '야당', '국회', '생각', '문재인', '공천', '의원', '새누리당', '지금', '여당', '국회의원', '박근혜', '좋다', '총선', '선진', '나라', '자다', '선거', '모르다', '화법', '호남', '문제', '국가', '김종인', '알다', '새누리', '보이', '인물', '인간', '친노', '철수', '친박', '민주', '자신', '바라다', '대한민국', '무슨', '인재', '정치인', '어떻다', '지역', '후보', '먹다', '정권', '출마', '주다', '민주당', '내다', '크다', '이준석', '정당', '오다', '리다', '가지', '소리', '정말', '지지', '반대', '세력', '대선', '없이', '모두', '탈당', '더불다']\n",
      "필수 단어가 병합된 상위 토큰 : ['국민', '정치', '사람', '김무성', '대통령', '안철수', '대표', '야당', '국회', '생각', '문재인', '공천', '의원', '새누리당', '지금', '여당', '국회의원', '박근혜', '좋다', '총선', '선진', '나라', '자다', '선거', '모르다', '화법', '호남', '문제', '국가', '김종인', '알다', '새누리', '보이', '인물', '인간', '친노', '철수', '친박', '민주', '자신', '바라다', '대한민국', '무슨', '인재', '정치인', '어떻다', '지역', '후보', '먹다', '정권', '출마', '주다', '민주당', '내다', '크다', '이준석', '정당', '오다', '리다', '가지', '소리', '정말', '지지', '반대', '세력', '대선', '없이', '모두', '탈당', '더불다', '동물', '짐승', '문희상', '아들', '세습', '논란', '불출마', '황교안', '친황', '청와대', '식물', '배신', '배제']\n",
      "공천 +  2016.01 83\n",
      "공천_빈도테이블_ 2016.01 >> [빈도 테이블.xlsx]백업 완료\n",
      "공천 2016.02  빈도 분석 수행\n",
      "\n",
      "3사 댓글 갯수 :  7029\n",
      "===== 1차 Tokenization 수행 시작 =====\n",
      "리플 수 = > 라인 수 :  7029\n",
      "4000 번째 라인 pos 필터링\n",
      "에러 라인 수:  0\n",
      "조사, 어미, 문장부호 제거 후\n",
      "리플 라인 예 =>  수출이 18.5%줄고 수입은 20%줄어 흑자기조 이여가 다행 이다  ===> pos 필터링 결과 예 => 수출 18.5% 줄 수입 20% 줄다 흑자 기조 이 여가 다행\n",
      "pos 필터링 결과     =====> <Text>객체화 합니다..\n",
      "pos 필터링 결과 예 :  수출 18.5% 줄 수입 20% 줄다 흑자 기조 이 여가 다행  ====> WholeText[0:20]... :  수출 18.5% 줄 수입 20% 줄다\n",
      "pos tagging 수행 =====>\n",
      "1. 토큰화 :  토큰 갯수 =====> 206485\n",
      "토큰 예시 : first_tokens[:10]... =>  ['수출', '18.5%', '줄', '수입', '20%', '줄다', '흑자', '기조', '이', '여가']\n",
      "2. 클렌징 수행, 1. 해부된 단어 재결합 + 한 글자, 숫자 filtering-out\n",
      "10000 번째 라인 재결합 작업\n",
      "20000 번째 라인 재결합 작업\n",
      "30000 번째 라인 재결합 작업\n",
      "40000 번째 라인 재결합 작업\n",
      "50000 번째 라인 재결합 작업\n",
      "60000 번째 라인 재결합 작업\n",
      "70000 번째 라인 재결합 작업\n",
      "80000 번째 라인 재결합 작업\n",
      "90000 번째 라인 재결합 작업\n",
      "100000 번째 라인 재결합 작업\n",
      "110000 번째 라인 재결합 작업\n",
      "120000 번째 라인 재결합 작업\n",
      "130000 번째 라인 재결합 작업\n",
      "140000 번째 라인 재결합 작업\n",
      "150000 번째 라인 재결합 작업\n",
      "160000 번째 라인 재결합 작업\n",
      "170000 번째 라인 재결합 작업\n",
      "180000 번째 라인 재결합 작업\n",
      "190000 번째 라인 재결합 작업\n",
      "200000 번째 라인 재결합 작업\n",
      "클렌징 후 토큰 수 :  156610\n",
      "3.  stopwords 제거\n",
      "3차 Tokens 갯수 : 123696\n",
      "1차 선별된 상위 토큰 : ['국민', '공천', '김무성', '사람', '대표', '정치', '대통령', '의원', '국회', '국회의원', '야당', '이한구', '선거', '새누리당', '생각', '김종인', '나라', '모르다', '자다', '지금', '총선', '좋다', '친박', '알다', '여당', '민주', '문재인', '국가', '새누리', '인간', '먹다', '문제', '대한민국', '인물', '보이', '내다', '주다', '유승민', '안철수', '박근혜', '무슨', '갈이', '친노', '자신', '민주당', '종북', '현역', '위원장', '상향식', '어떻다', '권력', '후보', '바라다', '정당', '우리', '오다', '더불다', '모두', '당선', '늘다', '정말', '지역', '리다', '없이', '정청래', '소리', '크다', '정권', '지지', '서다']\n",
      "필수 단어가 병합된 상위 토큰 : ['국민', '공천', '김무성', '사람', '대표', '정치', '대통령', '의원', '국회', '국회의원', '야당', '이한구', '선거', '새누리당', '생각', '김종인', '나라', '모르다', '자다', '지금', '총선', '좋다', '친박', '알다', '여당', '민주', '문재인', '국가', '새누리', '인간', '먹다', '문제', '대한민국', '인물', '보이', '내다', '주다', '유승민', '안철수', '박근혜', '무슨', '갈이', '친노', '자신', '민주당', '종북', '현역', '위원장', '상향식', '어떻다', '권력', '후보', '바라다', '정당', '우리', '오다', '더불다', '모두', '당선', '늘다', '정말', '지역', '리다', '없이', '정청래', '소리', '크다', '정권', '지지', '서다', '동물', '짐승', '문희상', '아들', '세습', '논란', '불출마', '황교안', '친황', '청와대', '식물', '배신', '배제']\n",
      "공천 +  2016.02 83\n",
      "공천_빈도테이블_ 2016.02 >> [빈도 테이블.xlsx]백업 완료\n",
      "공천 2016.03  빈도 분석 수행\n",
      "\n",
      "3사 댓글 갯수 :  22093\n",
      "===== 1차 Tokenization 수행 시작 =====\n",
      "리플 수 = > 라인 수 :  22093\n",
      "4000 번째 라인 pos 필터링\n",
      "8000 번째 라인 pos 필터링\n",
      "12000 번째 라인 pos 필터링\n",
      "16000 번째 라인 pos 필터링\n",
      "20000 번째 라인 pos 필터링\n",
      "에러 라인 수:  0\n",
      "조사, 어미, 문장부호 제거 후\n",
      "리플 라인 예 =>  현역의원들이란 아미 지역구민들의 선택을 받았던 사람이다. 변고가 없었다면 당연히 유라해야 한다. 그리고 친박이 원하는 100% 여론조사에서는 야당지지자들이 경쟁력 없는 후보에게 표를 몰아줄 개연성이 높다. 청와대는 권력욕을 버리고 나라를 위해 한 발 물러서야한다. 이 모든 갈등이 박근혜의 종신집권야욕에서 비롯된 것이다.  ===> pos 필터링 결과 예 => 현역 의원 들 아미 지역 구민 들 선택 받다 사람 변 고가 없다 당연하다 유라 하다 하다 그리고 친박 원하다 100% 여론조사 야당 지지자 들 경쟁력 없다 후보 표 몰다 개연 성 높다 청와대 권력 욕 버리다 나라 위해 하다 발 물러서다 하다 이 모든 갈등 박근혜 종신 집권 야욕 비롯 되다 것\n",
      "pos 필터링 결과     =====> <Text>객체화 합니다..\n",
      "pos 필터링 결과 예 :  현역 의원 들 아미 지역 구민 들 선택 받다 사람 변 고가 없다 당연하다 유라 하다 하다 그리고 친박 원하다 100% 여론조사 야당 지지자 들 경쟁력 없다 후보 표 몰다 개연 성 높다 청와대 권력 욕 버리다 나라 위해 하다 발 물러서다 하다 이 모든 갈등 박근혜 종신 집권 야욕 비롯 되다 것  ====> WholeText[0:20]... :  현역 의원 들 아미 지역 구민 들 선\n",
      "pos tagging 수행 =====>\n",
      "1. 토큰화 :  토큰 갯수 =====> 606513\n",
      "토큰 예시 : first_tokens[:10]... =>  ['현역', '의원', '들', '아미', '지역', '구민', '들', '선택', '받다', '사람']\n",
      "2. 클렌징 수행, 1. 해부된 단어 재결합 + 한 글자, 숫자 filtering-out\n",
      "10000 번째 라인 재결합 작업\n",
      "20000 번째 라인 재결합 작업\n",
      "30000 번째 라인 재결합 작업\n",
      "40000 번째 라인 재결합 작업\n",
      "50000 번째 라인 재결합 작업\n",
      "60000 번째 라인 재결합 작업\n",
      "70000 번째 라인 재결합 작업\n",
      "80000 번째 라인 재결합 작업\n",
      "90000 번째 라인 재결합 작업\n",
      "100000 번째 라인 재결합 작업\n",
      "110000 번째 라인 재결합 작업\n",
      "120000 번째 라인 재결합 작업\n",
      "130000 번째 라인 재결합 작업\n",
      "140000 번째 라인 재결합 작업\n",
      "150000 번째 라인 재결합 작업\n",
      "160000 번째 라인 재결합 작업\n",
      "170000 번째 라인 재결합 작업\n",
      "180000 번째 라인 재결합 작업\n",
      "190000 번째 라인 재결합 작업\n",
      "200000 번째 라인 재결합 작업\n",
      "210000 번째 라인 재결합 작업\n",
      "220000 번째 라인 재결합 작업\n",
      "230000 번째 라인 재결합 작업\n",
      "240000 번째 라인 재결합 작업\n",
      "250000 번째 라인 재결합 작업\n",
      "260000 번째 라인 재결합 작업\n",
      "270000 번째 라인 재결합 작업\n",
      "280000 번째 라인 재결합 작업\n",
      "290000 번째 라인 재결합 작업\n",
      "300000 번째 라인 재결합 작업\n",
      "310000 번째 라인 재결합 작업\n",
      "320000 번째 라인 재결합 작업\n",
      "330000 번째 라인 재결합 작업\n",
      "340000 번째 라인 재결합 작업\n",
      "350000 번째 라인 재결합 작업\n",
      "360000 번째 라인 재결합 작업\n",
      "370000 번째 라인 재결합 작업\n",
      "380000 번째 라인 재결합 작업\n",
      "390000 번째 라인 재결합 작업\n",
      "400000 번째 라인 재결합 작업\n",
      "410000 번째 라인 재결합 작업\n",
      "420000 번째 라인 재결합 작업\n",
      "430000 번째 라인 재결합 작업\n",
      "440000 번째 라인 재결합 작업\n",
      "450000 번째 라인 재결합 작업\n",
      "460000 번째 라인 재결합 작업\n",
      "470000 번째 라인 재결합 작업\n",
      "480000 번째 라인 재결합 작업\n",
      "490000 번째 라인 재결합 작업\n",
      "500000 번째 라인 재결합 작업\n",
      "510000 번째 라인 재결합 작업\n",
      "520000 번째 라인 재결합 작업\n",
      "530000 번째 라인 재결합 작업\n",
      "540000 번째 라인 재결합 작업\n",
      "550000 번째 라인 재결합 작업\n",
      "560000 번째 라인 재결합 작업\n",
      "570000 번째 라인 재결합 작업\n",
      "580000 번째 라인 재결합 작업\n",
      "590000 번째 라인 재결합 작업\n",
      "600000 번째 라인 재결합 작업\n",
      "클렌징 후 토큰 수 :  462494\n",
      "3.  stopwords 제거\n",
      "3차 Tokens 갯수 : 364099\n",
      "1차 선별된 상위 토큰 : ['국민', '사람', '대통령', '정치', '공천', '대표', '유승민', '김무성', '새누리당', '생각', '야당', '박근혜', '김종인', '의원', '이한구', '인간', '친박', '국회의원', '나라', '모르다', '자다', '선거', '새누리', '지금', '국회', '알다', '윤상현', '여당', '좋다', '먹다', '민주', '국가', '대한민국', '문제', '어떻다', '정청래', '보이', '주다', '총선', '문재인', '자신', '안철수', '무슨', '정말', '후보', '내다', '친노', '막말', '탈락', '소리', '오다', '리다', '민주당', '당선', '정권', '지지', '모두', '바라다', '언론', '권력', '크다', '정당', '인물', '보수', '없이', '정부', '지역', '대구', '탈당', '가지']\n",
      "필수 단어가 병합된 상위 토큰 : ['국민', '사람', '대통령', '정치', '공천', '대표', '유승민', '김무성', '새누리당', '생각', '야당', '박근혜', '김종인', '의원', '이한구', '인간', '친박', '국회의원', '나라', '모르다', '자다', '선거', '새누리', '지금', '국회', '알다', '윤상현', '여당', '좋다', '먹다', '민주', '국가', '대한민국', '문제', '어떻다', '정청래', '보이', '주다', '총선', '문재인', '자신', '안철수', '무슨', '정말', '후보', '내다', '친노', '막말', '탈락', '소리', '오다', '리다', '민주당', '당선', '정권', '지지', '모두', '바라다', '언론', '권력', '크다', '정당', '인물', '보수', '없이', '정부', '지역', '대구', '탈당', '가지', '동물', '짐승', '문희상', '아들', '세습', '논란', '불출마', '황교안', '친황', '청와대', '식물', '배신', '배제']\n",
      "공천 +  2016.03 83\n",
      "공천_빈도테이블_ 2016.03 >> [빈도 테이블.xlsx]백업 완료\n",
      "공천 2019.10  빈도 분석 수행\n",
      "\n",
      "3사 댓글 갯수 :  3362\n",
      "===== 1차 Tokenization 수행 시작 =====\n",
      "리플 수 = > 라인 수 :  3362\n",
      "에러 라인 수:  0\n",
      "조사, 어미, 문장부호 제거 후\n",
      "리플 라인 예 =>  그 시퍼런 무서운 권력을 가졌던 절대왕정도 시민의 힘으로 무너졌었다. 바닥민심을 얕보고 저런 얕은 수나 써서 잠깐 어찌 햅느려는게 과연 얼마나 갈수 있을지?저렇게라도 편법을 동원해서 개떡같은 거쌔보라지 사람마믄 다 똑같다. 추잡고 더럽고 한심한것에는 침을 뱉고 욕을 해줄뿐. 퉤퉤...  ===> pos 필터링 결과 예 => 그 시퍼렇다 무섭다 권력 가지다 절대왕정 시민 힘 무너지다 바닥 민심 얕다 보고 저런 얕다 수나 써다 잠깐 어찌 햅 느리다 과연 얼마나 갈수 있다 저렇다 편법 동원 하다 개떡같다 거쌔보 사람 마 믄 다 똑같다 추잡 더럽다 한심하다 침 뱉다 욕 해주다 뿐 퉤퉤\n",
      "pos 필터링 결과     =====> <Text>객체화 합니다..\n",
      "pos 필터링 결과 예 :  그 시퍼렇다 무섭다 권력 가지다 절대왕정 시민 힘 무너지다 바닥 민심 얕다 보고 저런 얕다 수나 써다 잠깐 어찌 햅 느리다 과연 얼마나 갈수 있다 저렇다 편법 동원 하다 개떡같다 거쌔보 사람 마 믄 다 똑같다 추잡 더럽다 한심하다 침 뱉다 욕 해주다 뿐 퉤퉤  ====> WholeText[0:20]... :  그 시퍼렇다 무섭다 권력 가지다 절대\n",
      "pos tagging 수행 =====>\n",
      "1. 토큰화 :  토큰 갯수 =====> 114982\n",
      "토큰 예시 : first_tokens[:10]... =>  ['그', '시퍼렇다', '무섭다', '권력', '가지', '다', '절대왕정', '시민', '힘', '무너지다']\n",
      "2. 클렌징 수행, 1. 해부된 단어 재결합 + 한 글자, 숫자 filtering-out\n",
      "10000 번째 라인 재결합 작업\n",
      "20000 번째 라인 재결합 작업\n",
      "30000 번째 라인 재결합 작업\n",
      "40000 번째 라인 재결합 작업\n",
      "50000 번째 라인 재결합 작업\n",
      "60000 번째 라인 재결합 작업\n",
      "70000 번째 라인 재결합 작업\n",
      "80000 번째 라인 재결합 작업\n",
      "90000 번째 라인 재결합 작업\n",
      "100000 번째 라인 재결합 작업\n",
      "110000 번째 라인 재결합 작업\n",
      "클렌징 후 토큰 수 :  86154\n",
      "3.  stopwords 제거\n",
      "3차 Tokens 갯수 : 69378\n",
      "1차 선별된 상위 토큰 : ['국민', '조국', '문재인', '사람', '정권', '민주당', '한국당', '나라', '정치', '지금', '대통령', '의원', '대한민국', '검찰', '인간', '생각', '총선', '이해찬', '좌파', '대표', '자유', '우리', '개혁', '알다', '주다', '문제', '국가', '더불다', '자다', '경찰', '먹다', '모르다', '좋다', '오다', '보수', '보이', '책임', '정신', '죽다', '내년', '무슨', '이철희', '내다', '집단', '권력', '어떻다', '국회의원', '국회', '탄핵', '모두', '너희', '여당', '정부', '집권', '지키다', '민주주의', '장관', '소리', '청와대', '망하다', '세력', '아직도', '다음', '황교안', '박근혜', '경제', '최고', '공천', '이낙연', '늘다']\n",
      "필수 단어가 병합된 상위 토큰 : ['국민', '조국', '문재인', '사람', '정권', '민주당', '한국당', '나라', '정치', '지금', '대통령', '의원', '대한민국', '검찰', '인간', '생각', '총선', '이해찬', '좌파', '대표', '자유', '우리', '개혁', '알다', '주다', '문제', '국가', '더불다', '자다', '경찰', '먹다', '모르다', '좋다', '오다', '보수', '보이', '책임', '정신', '죽다', '내년', '무슨', '이철희', '내다', '집단', '권력', '어떻다', '국회의원', '국회', '탄핵', '모두', '너희', '여당', '정부', '집권', '지키다', '민주주의', '장관', '소리', '청와대', '망하다', '세력', '아직도', '다음', '황교안', '박근혜', '경제', '최고', '공천', '이낙연', '늘다', '동물', '짐승', '문희상', '아들', '세습', '논란', '불출마', '친황', '식물', '배신', '배제']\n",
      "공천 +  2019.10 81\n",
      "공천_빈도테이블_ 2019.10 >> [빈도 테이블.xlsx]백업 완료\n",
      "공천 2019.11  빈도 분석 수행\n",
      "\n",
      "3사 댓글 갯수 :  7506\n",
      "===== 1차 Tokenization 수행 시작 =====\n",
      "리플 수 = > 라인 수 :  7506\n",
      "4000 번째 라인 pos 필터링\n",
      "에러 라인 수:  0\n",
      "조사, 어미, 문장부호 제거 후\n",
      "리플 라인 예 =>  나경원의 정신세계를 보았다. 진짜 공감능력 없는 겉똑똑이 정치인이다. 국민은 이런사람 외면한다. 나경원은 정치생명 끝이다. 당장 원내대표 바꿔야 한국당이 산다. 안그러면 민주당에게 장기집권 내주는거다. 나경원 안된다. 황교안도 안된다. 내눈엔 그렇게 보인다.  ===> pos 필터링 결과 예 => 나경원 정신 세계 보다 진짜 공감 능력 없다 겉 똑똑이 정치인 국민 이런 사람 외면 하다 나경원 정치 생명 끝 당장 원내대표 바꾸다 한국 당 산다 안 그렇다 민주당 장기 집권 내주다 나경원 안되다 황교안 안되다 내 눈 그렇게 보이다\n",
      "pos 필터링 결과     =====> <Text>객체화 합니다..\n",
      "pos 필터링 결과 예 :  나경원 정신 세계 보다 진짜 공감 능력 없다 겉 똑똑이 정치인 국민 이런 사람 외면 하다 나경원 정치 생명 끝 당장 원내대표 바꾸다 한국 당 산다 안 그렇다 민주당 장기 집권 내주다 나경원 안되다 황교안 안되다 내 눈 그렇게 보이다  ====> WholeText[0:20]... :  나경원 정신 세계 보다 진짜 공감 능\n",
      "pos tagging 수행 =====>\n",
      "1. 토큰화 :  토큰 갯수 =====> 243405\n",
      "토큰 예시 : first_tokens[:10]... =>  ['나경원', '정신', '세계', '보다', '진짜', '공감', '능력', '없다', '겉', '똑똑이']\n",
      "2. 클렌징 수행, 1. 해부된 단어 재결합 + 한 글자, 숫자 filtering-out\n",
      "10000 번째 라인 재결합 작업\n",
      "20000 번째 라인 재결합 작업\n",
      "30000 번째 라인 재결합 작업\n",
      "40000 번째 라인 재결합 작업\n",
      "50000 번째 라인 재결합 작업\n",
      "60000 번째 라인 재결합 작업\n",
      "70000 번째 라인 재결합 작업\n",
      "80000 번째 라인 재결합 작업\n",
      "90000 번째 라인 재결합 작업\n",
      "100000 번째 라인 재결합 작업\n",
      "110000 번째 라인 재결합 작업\n",
      "120000 번째 라인 재결합 작업\n",
      "130000 번째 라인 재결합 작업\n",
      "140000 번째 라인 재결합 작업\n",
      "150000 번째 라인 재결합 작업\n",
      "160000 번째 라인 재결합 작업\n",
      "170000 번째 라인 재결합 작업\n",
      "180000 번째 라인 재결합 작업\n",
      "190000 번째 라인 재결합 작업\n",
      "200000 번째 라인 재결합 작업\n",
      "210000 번째 라인 재결합 작업\n",
      "220000 번째 라인 재결합 작업\n",
      "230000 번째 라인 재결합 작업\n",
      "240000 번째 라인 재결합 작업\n",
      "클렌징 후 토큰 수 :  184221\n",
      "3.  stopwords 제거\n",
      "3차 Tokens 갯수 : 146865\n",
      "1차 선별된 상위 토큰 : ['국민', '한국당', '보수', '탄핵', '정권', '문재인', '사람', '정치', '나라', '대통령', '박근혜', '대표', '총선', '황교안', '지금', '대한민국', '통합', '생각', '자유', '좌파', '김무성', '의원', '유승민', '우파', '인간', '선거', '민주당', '조국', '모르다', '자다', '알다', '먹다', '우리', '좋다', '모두', '문제', '보이', '조선일보', '국회의원', '공천', '바라다', '야당', '이기', '정신', '어떻다', '지지', '국가', '홍준표', '무슨', '주다', '이상', '내년', '세력', '정당', '오다', '정말', '출마', '내다', '나가다', '박찬주', '다시', '죽다', '언론', '크다', '대한', '소리', '리다', '청와대', '자신', '모든']\n",
      "필수 단어가 병합된 상위 토큰 : ['국민', '한국당', '보수', '탄핵', '정권', '문재인', '사람', '정치', '나라', '대통령', '박근혜', '대표', '총선', '황교안', '지금', '대한민국', '통합', '생각', '자유', '좌파', '김무성', '의원', '유승민', '우파', '인간', '선거', '민주당', '조국', '모르다', '자다', '알다', '먹다', '우리', '좋다', '모두', '문제', '보이', '조선일보', '국회의원', '공천', '바라다', '야당', '이기', '정신', '어떻다', '지지', '국가', '홍준표', '무슨', '주다', '이상', '내년', '세력', '정당', '오다', '정말', '출마', '내다', '나가다', '박찬주', '다시', '죽다', '언론', '크다', '대한', '소리', '리다', '청와대', '자신', '모든', '동물', '짐승', '문희상', '아들', '세습', '논란', '불출마', '친황', '식물', '배신', '배제']\n",
      "공천 +  2019.11 81\n",
      "공천_빈도테이블_ 2019.11 >> [빈도 테이블.xlsx]백업 완료\n",
      "공천 2019.12  빈도 분석 수행\n",
      "\n",
      "3사 댓글 갯수 :  5958\n",
      "===== 1차 Tokenization 수행 시작 =====\n",
      "리플 수 = > 라인 수 :  5958\n",
      "4000 번째 라인 pos 필터링\n",
      "에러 라인 수:  0\n",
      "조사, 어미, 문장부호 제거 후\n",
      "리플 라인 예 =>  헌법을 파괴한 행위다. 즉시 탄핵하여 감옥으로 보내야 한다.  ===> pos 필터링 결과 예 => 헌법 파괴 행위 즉시 탄핵 하다 감옥 보내다 하다\n",
      "pos 필터링 결과     =====> <Text>객체화 합니다..\n",
      "pos 필터링 결과 예 :  헌법 파괴 행위 즉시 탄핵 하다 감옥 보내다 하다  ====> WholeText[0:20]... :  헌법 파괴 행위 즉시 탄핵 하다 감옥\n",
      "pos tagging 수행 =====>\n",
      "1. 토큰화 :  토큰 갯수 =====> 158830\n",
      "토큰 예시 : first_tokens[:10]... =>  ['헌법', '파괴', '행위', '즉시', '탄핵', '하다', '감옥', '보내다', '하다', '518']\n",
      "2. 클렌징 수행, 1. 해부된 단어 재결합 + 한 글자, 숫자 filtering-out\n",
      "10000 번째 라인 재결합 작업\n",
      "20000 번째 라인 재결합 작업\n",
      "30000 번째 라인 재결합 작업\n",
      "40000 번째 라인 재결합 작업\n",
      "50000 번째 라인 재결합 작업\n",
      "60000 번째 라인 재결합 작업\n",
      "70000 번째 라인 재결합 작업\n",
      "80000 번째 라인 재결합 작업\n",
      "90000 번째 라인 재결합 작업\n",
      "100000 번째 라인 재결합 작업\n",
      "110000 번째 라인 재결합 작업\n",
      "120000 번째 라인 재결합 작업\n",
      "130000 번째 라인 재결합 작업\n",
      "140000 번째 라인 재결합 작업\n",
      "150000 번째 라인 재결합 작업\n",
      "클렌징 후 토큰 수 :  120566\n",
      "3.  stopwords 제거\n",
      "3차 Tokens 갯수 : 96705\n",
      "1차 선별된 상위 토큰 : ['국민', '문재인', '정권', '나라', '선거', '대통령', '탄핵', '한국당', '사람', '정치', '문희상', '지금', '청와대', '대한민국', '검찰', '박근혜', '인간', '생각', '대표', '아들', '경찰', '알다', '국회', '모르다', '민주당', '자유', '농단', '국정', '자다', '돼지', '좌파', '국회의장', '먹다', '세습', '좋다', '총선', '바라다', '권력', '국회의원', '어떻다', '자리', '공천', '국가', '주다', '조국', '개입', '모두', '민주주의', '의원', '정말', '당선', '문제', '보이', '무슨', '황교안', '수사', '보수', '울산', '부정선거', '송철호', '시장', '야하다', '우리', '의장', '더럽다', '선거법', '생기', '리다', '공작', '정의']\n",
      "필수 단어가 병합된 상위 토큰 : ['국민', '문재인', '정권', '나라', '선거', '대통령', '탄핵', '한국당', '사람', '정치', '문희상', '지금', '청와대', '대한민국', '검찰', '박근혜', '인간', '생각', '대표', '아들', '경찰', '알다', '국회', '모르다', '민주당', '자유', '농단', '국정', '자다', '돼지', '좌파', '국회의장', '먹다', '세습', '좋다', '총선', '바라다', '권력', '국회의원', '어떻다', '자리', '공천', '국가', '주다', '조국', '개입', '모두', '민주주의', '의원', '정말', '당선', '문제', '보이', '무슨', '황교안', '수사', '보수', '울산', '부정선거', '송철호', '시장', '야하다', '우리', '의장', '더럽다', '선거법', '생기', '리다', '공작', '정의', '동물', '짐승', '논란', '불출마', '친황', '식물', '배신', '배제']\n",
      "공천 +  2019.12 78\n",
      "공천_빈도테이블_ 2019.12 >> [빈도 테이블.xlsx]백업 완료\n",
      "공천 2016.04  빈도 분석 수행\n",
      "\n",
      "3사 댓글 갯수 :  18\n",
      "===== 1차 Tokenization 수행 시작 =====\n",
      "리플 수 = > 라인 수 :  18\n",
      "에러 라인 수:  0\n",
      "조사, 어미, 문장부호 제거 후\n",
      "리플 라인 예 =>     ===> pos 필터링 결과 예 => \n",
      "pos 필터링 결과     =====> <Text>객체화 합니다..\n",
      "pos 필터링 결과 예 :    ====> WholeText[0:20]... :  \n",
      "pos tagging 수행 =====>\n",
      "1. 토큰화 :  토큰 갯수 =====> 0\n",
      "토큰 예시 : first_tokens[:10]... =>  []\n",
      "2. 클렌징 수행, 1. 해부된 단어 재결합 + 한 글자, 숫자 filtering-out\n",
      "클렌징 후 토큰 수 :  0\n",
      "3.  stopwords 제거\n",
      "3차 Tokens 갯수 : 0\n",
      "1차 선별된 상위 토큰 : []\n",
      "필수 단어가 병합된 상위 토큰 : ['동물', '짐승', '문희상', '아들', '세습', '논란', '불출마', '황교안', '친황', '청와대', '문재인', '식물', '배신', '배제']\n",
      "공천 +  2016.04 14\n",
      "공천_빈도테이블_ 2016.04 >> [빈도 테이블.xlsx]백업 완료\n",
      "공천 2019.09  빈도 분석 수행\n",
      "\n",
      "3사 댓글 갯수 :  1\n",
      "===== 1차 Tokenization 수행 시작 =====\n",
      "리플 수 = > 라인 수 :  1\n",
      "에러 라인 수:  0\n",
      "조사, 어미, 문장부호 제거 후\n",
      "리플 라인 예 =>  지금도.한개인이 당을 좌지우지 하는가. 안철수뭐고.유승민은 도 뮈인가. 하여튼 이런 인간들이 정치 한다고 그러니.나라가 개판이 되지. 손학규가 싫으면 당헌.당규에 의해 처리해야지.이게 무슨 꼴인가. 한심한 정당 정치  ===> pos 필터링 결과 예 => 지금 한 개인 당 좌지우지 하다 안철수 뭐 유승민 도 뮈 하여튼 이렇다 인간 들 정치 하다 그렇다 나라 개판 되다 손학규 싫다 당 헌 당 규 의하다 처리 하다 이 무슨 꼴 한심하다 정당 정치\n",
      "pos 필터링 결과     =====> <Text>객체화 합니다..\n",
      "pos 필터링 결과 예 :  지금 한 개인 당 좌지우지 하다 안철수 뭐 유승민 도 뮈 하여튼 이렇다 인간 들 정치 하다 그렇다 나라 개판 되다 손학규 싫다 당 헌 당 규 의하다 처리 하다 이 무슨 꼴 한심하다 정당 정치  ====> WholeText[0:20]... :  지금 한 개인 당 좌지우지 하다 안철\n",
      "pos tagging 수행 =====>\n",
      "1. 토큰화 :  토큰 갯수 =====> 36\n",
      "토큰 예시 : first_tokens[:10]... =>  ['지금', '한', '개인', '당', '좌지우지', '하다', '안철수', '뭐', '유승민', '도']\n",
      "2. 클렌징 수행, 1. 해부된 단어 재결합 + 한 글자, 숫자 filtering-out\n",
      "클렌징 후 토큰 수 :  24\n",
      "3.  stopwords 제거\n",
      "3차 Tokens 갯수 : 18\n",
      "1차 선별된 상위 토큰 : ['정치', '지금', '개인', '좌지우지', '안철수', '유승민', '하여튼', '인간', '나라', '개판', '손학규', '싫다', '의하다', '처리', '무슨', '한심하다', '정당']\n",
      "필수 단어가 병합된 상위 토큰 : ['정치', '지금', '개인', '좌지우지', '안철수', '유승민', '하여튼', '인간', '나라', '개판', '손학규', '싫다', '의하다', '처리', '무슨', '한심하다', '정당', '동물', '짐승', '문희상', '아들', '세습', '논란', '불출마', '황교안', '친황', '청와대', '문재인', '식물', '배신', '배제']\n",
      "공천 +  2019.09 31\n",
      "공천_빈도테이블_ 2019.09 >> [빈도 테이블.xlsx]백업 완료\n"
     ]
    }
   ],
   "source": [
    "Target_keyword = '공천'\n",
    "\n",
    "for each_month in every_months: # 위에서 나온 월별 값을 하나씩 받습니다. # ['2016.01', '2016.02', .. ,'2019.12']\n",
    "\n",
    "    print(Target_keyword, str(each_month), ' 빈도 분석 수행\\n')\n",
    "    total_lines = total.loc[total.rp_date == each_month,'rp_text']\n",
    "\n",
    "    total_lines.reset_index(drop = True, inplace = True)\n",
    "    total_lines = list(map(lambda x : str(x).replace('\\r','').replace('\\n','').replace('@','').replace('*','') , total_lines))   \n",
    "\n",
    "    print('3사 댓글 갯수 : ',len(total_lines))\n",
    "\n",
    "    # ========================== 월별 NLP 수행 ==========================\n",
    "    # '공천'에 대한 빅데이터 분석 \n",
    "    \n",
    "    # 1차 분류를 넣을 리스트\n",
    "    results = []\n",
    "    lines = total_lines\n",
    "    # 돌아가지 않은 리스트를 넣을 리스트\n",
    "    error_lines = []\n",
    "\n",
    "    print(' \\n task1 : 불필요한 품사 제거     ===== \\n')\n",
    "    print('리플 수 : ',len(lines))\n",
    "\n",
    "    line_idx = 0\n",
    "    for line in lines: # line = 리플 하나(ex:'둘 다 죽어줘야 국민들이 행복... 중략... ㅎㅎㅎ')씩 받아서\n",
    "        try:\n",
    "            malist = okt.pos(line, norm=True, stem=True) # 매 문장 마다 pos tagging하면...\n",
    "            # malist = [ ('죽다', 'Verb'),('국민', 'Noun'),...] 이런 형태가 되고\n",
    "            r= []                 \n",
    "            for word in malist:\n",
    "                if not word[1] in [\"Josa\", \"Eomi\", \"Punctuation\"]: # 조사,어미,문장부호를 뺀 나머지만 담아서\n",
    "                    r.append(word[0])\n",
    "\n",
    "            r1 = (\" \".join(r)).strip()\n",
    "            results.append(r1)\n",
    "        except:\n",
    "            error_lines.append(line)\n",
    "        # 작업 진행 정도를 보기위해 50,000번째 리플마다 print\n",
    "        line_idx += 1\n",
    "        if (line_idx % 10000) ==0 :\n",
    "            print(str(line_idx),'번째 리플까지   ---->   pos 필터링')\n",
    "\n",
    "    print('pos태깅 에러 라인 수: ', len(error_lines) )    \n",
    "    print('조사, 어미, 문장부호 제거 후')\n",
    "    print('ex) 0번째 리플 : ',lines[0],'\\n     ====> pos 필터링 후 =>', results[0])\n",
    "\n",
    "\n",
    "    # 조사, 어미, 문장부호를 뺀 리스트 요소를 > 하나의 text 객체로 만든다\n",
    "    WholeText = \"\".join(results) # result원소 하나하나로 쪼개져 있는 리플들을 모두 join 합니다. \n",
    "    print('\\n     ====> WholeText[0:20]... : ',WholeText[:20])\n",
    "\n",
    "    # 다시 형태소 단위로만 만들어서\n",
    "    first_tokens = okt.morphs(WholeText)\n",
    "    print('\\n 1. Tokenization : \\n   토큰 갯수 =====>',len(first_tokens))\n",
    "    print('ex) : first_tokens[:10]... => ',first_tokens[:10])\n",
    "\n",
    "    ### > 2차 클랜징\n",
    "    print('\\n 2. 클렌징 : task2+3. 해부된 단어 재결합 + 한 글자, 숫자 filtering-out')\n",
    "    # task2. De-dissectification >>> 너무 쪼개진 단어를 강제로 복원시킨다.\n",
    "    line_idx = 0\n",
    "    for i in range(len(first_tokens)):\n",
    "        len(first_tokens) / \n",
    "        if i != int(len(first_tokens) -1):\n",
    "            if (first_tokens[i] == '창')&(first_tokens[i+1] == '당하다')  :\n",
    "                first_tokens[i] = '창당'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '소')&(first_tokens[i+1] == '리지')  :\n",
    "                first_tokens[i] = '소리'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '한국')&(first_tokens[i+1] == '당')  :\n",
    "                first_tokens[i] = '한국당'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '친')&(first_tokens[i+1] == '문')  :\n",
    "                first_tokens[i] = '친문'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '지')&(first_tokens[i+1] == '지층')  :\n",
    "                first_tokens[i] = '지지층'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif first_tokens[i] == '태경':\n",
    "                first_tokens[i] = '하태경'\n",
    "            elif first_tokens[i] == '유투브':\n",
    "                first_tokens[i] = '유튜브'\n",
    "            elif (first_tokens[i] == '자')&(first_tokens[i+1] == '한')  :\n",
    "                first_tokens[i] = '자한당'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '불출')&(first_tokens[i+1] == '마는')  :\n",
    "                first_tokens[i] = '불출마'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '불출')&(first_tokens[i+1] == '마르다')  :\n",
    "                first_tokens[i] = '불출마'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '불')&(first_tokens[i+1] == '출마')  :\n",
    "                first_tokens[i] = '불출마'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '소')&(first_tokens[i+1] == '신')  :\n",
    "                first_tokens[i] = '소신'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '신')&(first_tokens[i+1] == '문')  :\n",
    "                first_tokens[i] = '신문'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '문')&(first_tokens[i+1] == '제인')  :\n",
    "                first_tokens[i] = '문재인'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '문')&(first_tokens[i+1] == '갈이')  :\n",
    "                first_tokens[i] = '물갈이'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '불출')&(first_tokens[i+1] == '마하')  :\n",
    "                first_tokens[i] = '불출마'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '불출')&(first_tokens[i+1] == '마로')  :\n",
    "                first_tokens[i] = '불출마'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '불출')&(first_tokens[i+1] == '마자')  :\n",
    "                first_tokens[i] = '불출마'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '불출')&(first_tokens[i+1] == '마한')  :\n",
    "                first_tokens[i] = '불출마'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '문')&(first_tokens[i+1] == '제')  :\n",
    "                first_tokens[i] = '문제'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '상향')&(first_tokens[i+1] == '식')  :\n",
    "                first_tokens[i] = '상향식'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '하향')&(first_tokens[i+1] == '식')  :\n",
    "                first_tokens[i] = '하향식'\n",
    "                first_tokens[i+1] = ' '\n",
    "            elif (first_tokens[i] == '무성'):\n",
    "                first_tokens[i] = '김무성'\n",
    "            line_idx += 1\n",
    "            if (line_idx % 50000) ==0 :\n",
    "                print(str(line_idx),'번째 Token 재결합 ')\n",
    "\n",
    "    # task3. 한 음절, 숫자는 filtering-out\n",
    "    first_tokens = list(filter(lambda x : (len(x) != 1) & (x.isdecimal()==False), first_tokens))\n",
    "    print('클렌징 후 토큰 수 : ',len(first_tokens))\n",
    "\n",
    "    # task4. 불용어 지정 \n",
    "    print('\\n task4.  stopwords 제거') # <<< 위에서 stop_words 변수 지정 했습니다.\n",
    "    first_tokens = [ind_token for ind_token in first_tokens if ind_token not in stop_words]\n",
    "    print('stopwords 제거 후 Tokens :',len(first_tokens))\n",
    "    print('ex) Tokens[:15] :',first_tokens[:15])\n",
    "\n",
    "    # 토큰 전체를 nltk.text의 인스턴스로 지정 해줘서 \n",
    "    text_object_name = Target_keyword + '_' + each_month\n",
    "    whole_tokens_text = nltk.Text(first_tokens, name =text_object_name)\n",
    "    # 빈도 선 그림을 그릴 때 nltk.Text(토큰)를 그대로 받아서 plotting을 하게 됩니다. \n",
    "    # 이때, 토큰은 > ['공천','공천','국회','안철수','안철수', ... '문재인', ...]\n",
    "    # 이런 형태로 있고 이걸, nltk.Text(위에 토큰들) 로 넣어주면 => <NLTK. TEXT ...> 형태의 객체가 됩니다.\n",
    "\n",
    "    #freq_rank_upto = 70 < 위에서 이렇게 지정하게 되고, 빈도가 높은 단어 70위 까지만 보관하게 됩니다.\n",
    "    token_backup_1 = whole_tokens_text.vocab().most_common(freq_rank_upto) \n",
    "    token_list_1 = [token[0] for token in token_backup_1] # < 70개의 토큰\n",
    "    freq_list_1 = [token[1] for token in token_backup_1] # < 70개의 토큰 별 counts 값\n",
    "\n",
    "    # 꼭 포함해주어야 하는 필수 단어를 새 리스트 안에 넣고자 합니다. \n",
    "    appndx_word_list = []\n",
    "    appndx_word_freq = []\n",
    "    \n",
    "    # task6 ) 빈도가 낮아도 빈도 카운트를 꼭 알아야하는 주요 단어를 포함시켜줍니다.\n",
    "    for ind_token in necessary_words: # < 위에서 지정한 necessary_words를 하나씩 받아서 \n",
    "        if ind_token not in token_list_1: # 상위 70위 단어 안에 없으면 \n",
    "            appndx_word_list.append(ind_token) # 새로 넣어줍니다. \n",
    "            ind_freq=whole_tokens_text.count(ind_token)\n",
    "            appndx_word_freq.append(ind_freq)\n",
    "\n",
    "    token_list_1.extend(appndx_word_list)\n",
    "    freq_list_1.extend(appndx_word_freq)\n",
    "    print('필수 단어가 병합된 상위 토큰 수 :',len(token_list_1))\n",
    "    \n",
    "    # task 5) 빈도 테이블을 xlsx로 백업합니다.!\n",
    "    backup_directory = '../' + Target_keyword + '_빈도_'+str(each_month)+'.xlsx'\n",
    "    pd.DataFrame({'words' : token_list_1,\n",
    "                  'freq':freq_list_1 }).to_excel(backup_directory, index = False)\n",
    "    print(Target_keyword, '_빈도테이블_', str(each_month),'>> [빈도 테이블.xlsx]백업 완료')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 추가 task 2)   \n",
    "* concordance 체크 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nltk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-173801c39648>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mwhole_tokens_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mText\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfirst_tokens\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m=\u001b[0m\u001b[1;34m'공천_조선+한국+한겨레_댓글'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nltk' is not defined"
     ]
    }
   ],
   "source": [
    "text_object_name = Target_keyword + '_' + each_month # ex ) '공천_2019.10'\n",
    "whole_tokens_text = nltk.Text(first_tokens, name = text_object_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 25 of 32 matches:\n",
      "다 의원 들 줄 세우다 정말 가다 떨다 앉다 김무성 이 전라도 갑부 아들 태어나다 이 세상 보여주다 아무 것 없다 부자 사실 아니다 모르다 \n",
      " 가볍다 뜻 크다 것 기대하다 틀리다 조선족 받아들이다 하다 김영삼 아들 늘다 이렇다 말 들 그 신뢰 하다 어렵다 하다 것 들 유 의원 하다\n",
      "끼 학교 아부지 맘 고생 시키다 보다 ㅎㅎㅎ ㅋㅋㅋ 왜럼 헌병 오장 아들 0 답 다 그 리다 그려슈 당신 그 리다 부르다 짓다 친일파 진정 \n",
      " 가지가지 하다 언제 다시 더 불당 복귀 하다 권력 재산 없다 사람 아들 구제 하다 위해 학교 찾다 가다 순수하다 부모 마음 되다 권력 있다\n",
      "출 선봉 장 자칭 하다 때 그때 누구 걸리다 그러나 악질 친일 헌병 아들 임 밝혀지다 아들 로우 스쿨 외압 관련 오히려 피해자 그걸 믿다 사\n",
      "하다 때 그때 누구 걸리다 그러나 악질 친일 헌병 아들 임 밝혀지다 아들 로우 스쿨 외압 관련 오히려 피해자 그걸 믿다 사람 있다 보다 모양\n",
      "범 출신 고문 자행 일본헌병 군조 지금 중사 시 케미 시 구 니 오 아들 신기남 억울하다 담 출마 준비 하라 입 있다 하다 말 없다 비리 의\n",
      "상임 명 심하다 뭐 장발장 정의 증말 소가 웃 일이 일본 순사 오장 아들 xxxxxx 야 국회의원 뱃지 빼다 그냥 조용하다 사라지다 보기 좋\n",
      "사라지다 보기 좋다 본인 좋다 것 인간 욕망 측은하다 정의 왜 헌병 아들 로서 남 친일파 매도 하다 당시 그 단어 생각 안 나다 난 정의 같\n",
      "신기남 아버지 일제시대 때 일본 압잡 이 국민 들 괴롭히다 이제 그 아들 신기남 로스쿨 청탁 의혹 로 로스쿨 학생 들 피 해주다 잘 하다 잘\n",
      " 법더 민주당 탈당 자다 결정 이 다 역시 친일 앞잡이 헌 병오 장 아들 답 구나 어디 붙다 것 안철수 모시 다 않다 따다 불 민주당 국민 \n",
      "기남 헌병 오장 이다 부친 띠 일본 망명 하다 하다 친일파 잔손 그 아들 당신 실제 억울 하다 수도 있다 문제 상대방 똑같이 억울 하다 수 \n",
      " 넘다 구케 들어가다 구케 하수도 더 더럽다 지역 구민 들 바보 니 아들 잘나다 ㅂ ㅅ ㅅ ㄲ 철수 꼬임 그간 마이 해뭇 다 무소속 출마 하\n",
      " 맨 드니 햇 갈리 다 정치권 너무 오래 동안 금 뱃지 갑질 해오다 아들 가다 논란 이미 지역 구민 신뢰 외 민생 챙기다 않다 국민 혈 세로\n",
      "떠나다 것 남다 아름답다 모습 ㅈㄹ 들다 하다 라이 일본 헌병 오장 아들 장발장 신기남 애비 친일 인명 사전 들다 친일 사전 기록 되어다 그\n",
      " 길 건너편 아파트 개인 적 시부모 님 같다 동 이웃 임 서초 살다 아들 따다 사람 들 물어보다 조윤선 장관 서초 딸 맞다 선거 하나 마나 \n",
      " 위해 물러나다 서초 참신하다 인물 조윤선 대세 선거 때 되다 무슨 아들 달 들 많이 나오다 솔직하다 바람나다 아들 딸 같다 걱정 되다 국회\n",
      "대세 선거 때 되다 무슨 아들 달 들 많이 나오다 솔직하다 바람나다 아들 딸 같다 걱정 되다 국회 으 원 외모 보다 차라리 미스코리아 후보 \n",
      "삼 이 아버지 유산 월 사 급 내다 정치 배우다 앵삼 이의 정치 적 아들 黨代表 오다 限時的 인 공 천 관리 위원장 級 이 다르다 같이 죽다\n",
      "자 누구 무신경 박정희 군사혁명 이후 오늘 당시 없다 삼 들 노가다 아들 남기다 가버리다 다행하다 아들 녀석 장가 가다 손자 더욱 힘들다 ㅡ\n",
      " 이후 오늘 당시 없다 삼 들 노가다 아들 남기다 가버리다 다행하다 아들 녀석 장가 가다 손자 더욱 힘들다 ㅡ 여 자칭 구 꿈 같다 노숙자 \n",
      "함부로 하다 김영삼 오기 김대중 정권 넘겨주다 당신 김영삼 정치 적 아들 더니 닮다 당신 아무리 해도 지지율 올라가다 않다 거기 대한 고민 \n",
      "우습다 꼴 당하다 오늘 그냥 나와라 문재인 불다 김치 국 말다 마노 아들 딸 목 힘 도주 양복 새롭다 한 벌 마 추다 구두 ？ M 아 놓다 \n",
      "전 노인 투표 하다 말 것 같다 고향이 아니다 적지 아니다 감 근데 아들 자다 두다 아비 국가 해 끼치다 아들 해병대 출신 야비하다 추잡하다\n",
      " 아니다 적지 아니다 감 근데 아들 자다 두다 아비 국가 해 끼치다 아들 해병대 출신 야비하다 추잡하다 정 ㄷㅇ 의 모습 그대로 드러나다 있\n",
      "None\n",
      "Displaying 25 of 76 matches:\n",
      " 아니다 뭐 하 정치 판 들어오다 김연아 추성훈 박찬호 류현진 박인비 아 그리고 트위터 대통령 이외수 칠성파 두목 미학 출신 이빨 진중권 국제\n",
      "다 얄팍하다 속셈 이한구 의하다 여지 없이 박살 날다 같다 안달 복달 아 권 지역별 단 일화 하다 새누리당 100 석도 못 건지다 이한구 박근\n",
      " 들 어찌 눈물 겹 않다 살다 돌다 오라 니 김무성 이 말 아직 공천 아 하다 그렇다 말 하다 때 아니다 김무성 씨 자기 유리하다 현역 의원 \n",
      "좀 마르다 으이 그 미련 것 들 박박 거리 니 들 모습 어떻다 비추다 아 보다 골빈 당원 들 같다 구 지지율 노랗다 물다 한참 떨어지다 하다 \n",
      "대통령 팔 면서 자 기계 파 올인 열중 대표 비서실 장 녀석 눈가 리 아 옹 식 변명 늘어놓다 그렇다 여당 야당 국회 자체 없애다 국민 들 이\n",
      "되다 한국 망하다 때리다 시어머니 말리 다 시누이 더 밉다 국민 바보 아 말 좋다 박 정부 성 공 타령 하 결국 대통령 위 서다 아니다 도대체\n",
      "국민 들 그 권력 필요하다 때 쓰다 5년 간 위임 해주다 이서 걸 0 아 즉 너 같다 얍잡 0 청소 하다 때 쓰다 알다 ㅇ 00 하다 0 아 \n",
      " 아 즉 너 같다 얍잡 0 청소 하다 때 쓰다 알다 ㅇ 00 하다 0 아 광주 6조 7천억 혈세 퍼 부어 세계 제일 크다 궁전 짖다 자네 같다\n",
      "국민 들 치르다 떨다 하다 누가 저 인간 금 배지 달다 이나라 이 꼴 아 대구 대구 하다 유승민 김부겸 라인 부산 영 도의 김무성 이어지다 매\n",
      "더 있다 나라 살림 거 덜다 순식간 수조 원 짜다 국민 혈세 낭비하다 아 문법 야당 만들다 준 인물 하다 소리치다 참으로 같잖다 지금 아 문법\n",
      "하다 아 문법 야당 만들다 준 인물 하다 소리치다 참으로 같잖다 지금 아 문법 만들어지다 시설 개점휴업 상태 더 앞 몇 년 간 수 천억 씩 계\n",
      " 외치 다 금수 저가 그렇다 구호 멋있다 보이 다 경제 어렵다 5조원 아 문법 통과 시키다 크다 힘 보태 호구 짓다 유승민 대 구 의원 들 이\n",
      "대한민국 자산 편 가르다 혈안 돼다 있다 최경환 유승민 발바닥 못 ？ 아 간다 나라 정부 박 대통령 국민 망하다 지역 지방 유권자 들 반 대표\n",
      "표 가다 공책 크기 거 기 다 휴대전화 없다 모바일 경선 안 하다 줄 아 일단 모든 투표 행위 재 검표 가능하다 선거 이후 벌어지다 부정선거 \n",
      "승민 이 저 성 과자 왜 저 성과 잔 국민 혈세 천문학 적 날다 먹다 아 문법 야당 뜻대로 밀다 붙이 다 통과 시키다 막대 성과 올 리다 말 \n",
      "아나다 생각 하다 파렴치하다 인간 지나다 않다 유성민 이 맘데 전라도 아 문법 만들다 국민 혈 세로 5조원 을 퍼 부다 말 있다 자신 키우다 \n",
      "다 상향 공천 꼼수 써다 대선 먹다 보다 크레믈린 같다 그 속 모르다 아 나 보다 ㅋ 새누리당 국회의원 출마 하다 재직 중 결격 사항 있다 사\n",
      "그거 없다당 대표 있다 공 천 위원 장이 있다 이한구 당 대표 뜻 ？ 아 사무 적 일 하다 각 예 하 지휘 관 제멋대로 하다 어쩌 자다 김무성\n",
      "긴것 들 김무성 이한구 최경환 유승민 김문수 이 것 들 다 경상도 들 아 박하다 매도 거기 지다 들다 끼리 치고받다 다른사람 끼 그 사람 매장\n",
      " 하노 비박 들 많이 당선 시키다 다음 대통령 후보 할라꼬 국민 바보 아 새누리 의원 들 절반 이상은 후보 공천 하다 안되다 당 대표 물 갈이\n",
      "하다 변절 하다 정말 눈물 겹 애쓰다 민주화 동지 들 가슴 치 다 거 아 여당 공천 왜 이렇다 박근헤 당시 다 죽다 한나라당 살리다 실력 자다\n",
      "니다 호가호위 하다 꼬락서니 ㅋㅋㅋ 저 사람 뻑하 자리 박차다 나가다 아 탈당 하다 웃기 다 X 김무성 이 싸움 상대 잘 못 고르다 상대 싸다\n",
      " 뭐 비박 뭐 난 그렇다 것 자다 모르다 하지만 반공 멸공 자다 안다 아 뭇 틀다 힘내다 김무성 무엇 국민 약속 하다 하다 툭하면 총선 패 하\n",
      "보다 물론 냉정하다 지기 힘들다 서도 짜다 식 들 문재인 믿다 까불다 아 이 좋다 고소하다 입 당시 비례대표 공천 보장 해주다 뒷 거래 없다 \n",
      " 마노 아들 딸 목 힘 도주 양복 새롭다 한 벌 마 추다 구두 ？ M 아 놓다 차도 한 대 빼놓다 이 젠 금뻬찌 달 되다 김종인 멀다 소리 정\n",
      "None\n",
      "Displaying 25 of 4200 matches:\n",
      "수출 18.5% 줄 수입 20% 줄다 흑자 기조 이 여가 다행 박사모 들 일제 히 설치 다 대다 기 다 려 1년 만 김 대표 친박비박 논 하다\n",
      " 김 대표 친박비박 논 하다 단합 하다 국민 점수 매기 있다 국회의원 들 너무 행패 부리고 사리 사욕 차려 무소속 참신하다 사람 들 확 바꾸다\n",
      " 국회의원 들 너무 행패 부리고 사리 사욕 차려 무소속 참신하다 사람 들 확 바꾸다 대한민국 잘 되다 이렇다 때 소신 있다 실력 있다 정직하다\n",
      "꾸다 대한민국 잘 되다 이렇다 때 소신 있다 실력 있다 정직하다 사람 들 많이 출마 하다 정치 판이 바뀌다 김무성 이 안 돼다 차라리 오세훈 \n",
      "세훈 이 나다 젊다 비 다 있다 ㅎㅎㅎ 비 박다 대변인 비 박다 패널 들 주로 끌다 모으다 1년 이상 박 대통령 친 박만 편파 적 비판 하다 \n",
      "다 아예 안 부르다 비 박다 패널 야당 성향 패널 로만 꾸리 다 친박 들 주로 비판 도르다 넘다 이렇다 행태 1년 이상 이 젠 강력 조치 하다\n",
      "넘다 이렇다 행태 1년 이상 이 젠 강력 조치 하다 하다 어이없다 니 들 어떻다 박 대통령 이름 들먹이다 하 극 상적 발언 행정부 권한 축소 \n",
      " 상적 발언 행정부 권한 축소 하다 국회법 개정안 통과 시키다 한 것 들 비 박다 니 들 박 대통령 이름 팔지마다 김무성 당 대표 인간 저렇게\n",
      "부 권한 축소 하다 국회법 개정안 통과 시키다 한 것 들 비 박다 니 들 박 대통령 이름 팔지마다 김무성 당 대표 인간 저렇게 저희 들 끼리 \n",
      "다 니 들 박 대통령 이름 팔지마다 김무성 당 대표 인간 저렇게 저희 들 끼리 따로 몰리 다 쑥덕거리다 당 되다 리가 있다 온갖 잡박 들 대통\n",
      "저희 들 끼리 따로 몰리 다 쑥덕거리다 당 되다 리가 있다 온갖 잡박 들 대통령 팔 먹다 모이 다 당 대표 저녁 한번 같이 한 게 뭔 대수 잡\n",
      "통령 팔 먹다 모이 다 당 대표 저녁 한번 같이 한 게 뭔 대수 잡박 들 열등감 토 하다 김무성 당 망치 본인 망가지다 수 없다 정신 상태 정\n",
      "다 ㅉㅉㅉ 머릿수 자랑 아니다 당 대표 로서 출전 하다 자기 당 후보 들 격려 하다 것 무슨 세 결합 통지 하다 대도 안 나오다 인사 들 다른\n",
      "후보 들 격려 하다 것 무슨 세 결합 통지 하다 대도 안 나오다 인사 들 다른 꿍꿍 이 있다 아니다 누구 이쁘다 받다 심산 일 수도 있다 김무\n",
      " 대통령 발목 잡다 나라 혼란 빠지다 하다 여당 3분 지 1 이 역적 들 어떻다 국회 제대로 돌아가다 수 있다 새누리당 권력자 치 다 명박 계\n",
      " 자랑 하다 정말 웃기 다 이 김무성 지도력 한계 명단 공개 해 역적 들 표 로서 심판 하다 박근혜 회장 님 밑 지역 보스 들 차기 회장 노리\n",
      " 공개 해 역적 들 표 로서 심판 하다 박근혜 회장 님 밑 지역 보스 들 차기 회장 노리 연장 들 서로 세력 과시 하다 싸우다 꼴 여자 대통령\n",
      "서 심판 하다 박근혜 회장 님 밑 지역 보스 들 차기 회장 노리 연장 들 서로 세력 과시 하다 싸우다 꼴 여자 대통령 문제점 여실히 자다 보여\n",
      "자다 돌아가다 저 멍청하다 김무성 이 번 선거 다 망치 다 보수 인사 들 속 뒤지다 지다 김무성 씨 그렇다 시간 있다 체육 계 연예계 얼굴 마\n",
      "최악 파트너 말 제발 정신 좀 차려 어디 비 박다 명단 좀 보다 당신 들 지난 총선 박 대통령 도움 없이 자력 국회의원 돼다 화장실 들어가다 \n",
      "회의원 돼다 화장실 들어가다 때 나오다 때 다른 전형 적 배신자 그룹 들 번 짓다 틀리다 그렇게 비난 받다 19 대다 국회의원 들 또 불다 들\n",
      "배신자 그룹 들 번 짓다 틀리다 그렇게 비난 받다 19 대다 국회의원 들 또 불다 들이다 하다 그 들 리그 를 정말 보고 싶다 않다 사람 말로\n",
      "다 그렇게 비난 받다 19 대다 국회의원 들 또 불다 들이다 하다 그 들 리그 를 정말 보고 싶다 않다 사람 말로 하다 수 있다 가장 강하다 \n",
      "권 친박 비 박의 그림자 서성거리다 이르다 내부 특단 용해 하다 야당 들 야권 이기 다 현 석수 월등하다 이기 다 선거 되어다 나라 현재 미래\n",
      " 정부 국민 모두 동반성 장 하다 각 지역 지방 종북 좌파 야당 의원 들 좌파 정권 들어서다 보라 나라 기울어지다 급기야 좌파 연 남북 연합 \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(whole_tokens_text.concordance(\"아들\"))\n",
    "print(whole_tokens_text.concordance(\"아\"))\n",
    "print(whole_tokens_text.concordance(\"들\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Displaying 8 of 8 matches:\n",
      " 득세 하다 나라 없다 북 잘 되다 동포 잘 되다 것 아니다 3 대 세습 득세 인민 노예 되다 그리고 우리 영원하다 중국 일본 묻히다 말다 \n",
      "다 더 민주 민주화 정의 무엇 자유민주 자유 빼 하다 전례 보아 북 세습 독재정 권 인민 민주주의 도 민주 포함 시키다 건가 자유 민주주의 \n",
      "리 대한민국 국민 일치단결 힘 뿐 중구 난방 이소리 저 소리 3 대 세습 3 대다 뚱보 좋아하다 소리 과거 발언 행동 어떠하다 이제 대한민국\n",
      "옛날 향수 젖다 분탕질 획책 하다 간 너희 교주 비참하다 최후 결과 세습 되다 것 알다 것비박 친박 갈다 수록 가관 박 대통령 마케팅 하다 \n",
      "다 임 의원님 수고 많이 하다 이 젠 북 가다 사다 북한 개혁 하다 세습 왕조 끊다 내다 민주 혁명 북조선 일으키다 한국 하다 북 서다 하다\n",
      " 한반도 미래 자신 들 권력 욕 앞세우다 때문 이북 김성주 3 대다 세습 독재 추종 하다 자 들 집단 구성 야당 행세 하다 있다 알다 최선 \n",
      "세력 탈락 시키다 남다 자도 없다 김홍걸 공천 하 김대중 인민공화국 세습 하다 장해 먹다 김종인 좋아하다 욕 잘 하다 놈 들 포함 하다 절반\n",
      "거 국민 들이다 바로 잡 라나 국제 테러 단체 이북 김성주 3 대다 세습 독재 추종 나라 뒤지다 엎 못 해 발악 하다 자 들 집단 구성 야당\n",
      "None\n",
      "Displaying 25 of 99 matches:\n",
      "아니다 당 대표 로서 출전 하다 자기 당 후보 들 격려 하다 것 무슨 세 결합 통지 하다 대도 안 나오다 인사 들 다른 꿍꿍 이 있다 아니다 \n",
      "OO 같다 패거리 정치 ㅡ 무대 배나무 밑 갓 끈 매다 말 속담 대하 세 삼 생각 하다 하다 예컨데 종북 떼법 정치 세력 언론 티끌 만 흠 잡\n",
      "굴 마 담들다 섭외 하다 시간 없다 같다 참으로 기 막히다 어제 23 세 축구 보다 2:0 이기 다 기고 만장 하다 2:3 무참 히 깨지다 꼴\n",
      "국민당 언론 크게 나오다 새누리당 조용하다 새롭다 능력자 들 영 입하 세 엄홍길 국회의원 하다 해도 자유 자질 되다 등산 외 무엇 알 잘 하다\n",
      "다 않다 웃다 살아가다 일만 남다 것 같다 19 대다 국회 제일 높다 세 놈 싸다 악 추다 뽑다 버리다 대통령 나무 그늘 아래 안주 하다 마땅\n",
      "비 다 사유 100 자평 삭제 하다 진박 너무 어지럽다 정치가 아무리 세 몰이 라지 어떻든 지금 같이 먹다 놀다 한 달 수천 만원 씩 세비 받\n",
      " 여당 의원 박근혜 정부 협조 하다 않다 자다 모조리 탈락 시키다 딱 세 사람 공천 제외 하다 새누리 총선 대승 하다 유승민 이재오 김무성 위\n",
      "갈이 하다 제 1 당 되다 수 있다 대표 아니다 독재자 나선 모 양일 세 쩝 공 천 위원장 맡기다 공 천 위원 장이 알 서하 계 간섭 하다 머\n",
      "성 무성 그 50 명중 누가 네 충성 하리 함부로 헛된짓 저지르다 내 세 울 만 공 적도 없이 충성 하다 장수도 없이 다만 편 들어주다 대로 \n",
      " 아니다 크다 인물 아니다 가다 김무성 공 천 학살 친 섬기다 모 양 세 내 오직 대통령 넘어서다 위해 완전 ㅉ ㅉ ㅉ 다 아무리 지지 하다 \n",
      " 없애다 되다 이 것 아니다 스포츠 연예인 등 얼굴 마담 영 입하 혈 세 낭비 본인 ○○ 취급 받다 바보 짓다 중단 하다 하다 새누리당 욕먹다\n",
      " 사회 살 볼 수 있다 권력 국민 나오다 그 국민 박근혜 대통령 뽑다 세 번의 시행착오 끝 대한민국 위태 상황 바로 잡다 하다 국민 마음 말 \n",
      "아니다 안되다 생각 뿐 40 대다 기 수론 말 하다 정치인 결국 80 세 되다 대통령 하다 당신 들 뭐 틀리다 뉴햄프셔 프라이머리 보다 투표 \n",
      " 거 무작정 여야 합의 파기 하다 것 들이다 특별나다 사유 없이 고액 세 비축 내미다 국 하다 반 대 투쟁 하다 저 질 들 전부 물 갈이 하란\n",
      "들 그 들 패권 위해 새누리당 ？？“？ 있다당 규 없다 짓 하다 하다 세 습독 제자 들 뭣 다르다 일 하다 인지 놀다 먹다 인지 국민 잘 모르\n",
      "받다 이외 나라 뭔가 기 여한 있다 할아버지 덕 이외 스스로 한일 내 세 워 하다 아니다 도데 체 이 사람 여기 저기 중용 되다 차다 이해 안\n",
      "그 후 신 의원님 조용하다 국가 위해 희생 봉사 하다 불다 어떻다 애 세 끼 학교 아부지 맘 고생 시키다 보다 ㅎㅎㅎ ㅋㅋㅋ 왜럼 헌병 오장 \n",
      "딸 같다 걱정 되다 국회 으 원 외모 보다 차라리 미스코리아 후보 내 세 우지 바른 말 자기 소신 있다 사람 뽑다 구민 4년 간 편하다 것 대\n",
      "당 자민련 같이 두 조각 나다 진보 다시 뭉치 다 1 당 되다 김무성 세 비축 내다 농땡 의원 들 탈락 시키다 고 인물 썩다 참신하다 새 인물\n",
      "대희 무식하다 천박하다 김무성 제안 거부 부산 해운대 나오다 하다 야 세 거 세다 서울 도전 힘겹다 없다 그건 그렇다 김무성 전라도 광주 출마\n",
      " 문제 내 부적 조용하다 보완 하다 방책 상의 지다 공개 적 계 파간 세 대결 하 듯이 하다 되다 더구나 당 임명 공 천 관리 위원 장이 당 \n",
      " 자꾸 왜 이르다 옜날 공천 한번 탈락 한 것 차다 뒤 끗긴 양 반일 세 당 대표 ㅡ 공 천 관리 위원장 이렇다 저렇다 하다 이 것 독재 아니\n",
      "와중 무슨 꼴 사납다 쌈 박다 국민 들 짜증나다 당내 정적 제거 위해 세 퍼트 키우다 같다 자기 손 피 흘리다 기 다 싫다 세 퍼트 힘 실어 \n",
      "정적 제거 위해 세 퍼트 키우다 같다 자기 손 피 흘리다 기 다 싫다 세 퍼트 힘 실어 주다 정적 물 게 괴롭히다 김무성 대표 로서 분통 터지\n",
      "는 국민 여론 80% 가다 넘다 모르다 없다 새 피 수혈 하다 새롭다 세 모으다 헌 피로 고지 넘다 수 없다 박정희 아집 박근혜 아집 서청원 \n",
      "None\n",
      "Displaying 5 of 5 matches:\n",
      "이렇게 갑론 박 하나요 우리나라 유권자 들 투표 행태 전혀 맞다 않다 습 ㄴ 그리고 가장 중요하다 여야 달다 전 출마 자의 동시 투표 여론조사\n",
      "다 총선 그 들 패거리 들 입당 자 들 끼우다 다 올라오다 다시 참모 습 종북 패권 발톱 드러내다 김종인 이 공천 통해 친노 패권 무리 들 통\n",
      " 정치 하다 한 무 ㅈㅇ 같다 넘다 들다 배척 공천 잘 하다이 것 ？ 습 結？ 아니다 정 ㅊ 김굉 ㅈ 진성준 어떻다 된거 유권자 뭔가 보여주다\n",
      "다 웃음 나오다 좀더 신중하다 하다 백성 들 기 대감 갖다 보고 있다 습 ㅏㄷ 김종인 별 이상하다 사람 다 보다 당신 비 대위 대표 그거 보다\n",
      " 아 재는 이미 영도다리 밑 떨어지다 겁니다 더 이한구 벌써 뽕 따다 습 더 김무성 대표 여기 물러서다 모든 것 끝나다 절대 진박 한 태 밀리\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(whole_tokens_text.concordance(\"세습\"))\n",
    "\n",
    "print(whole_tokens_text.concordance(\"세\"))\n",
    "print(whole_tokens_text.concordance(\"습\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
