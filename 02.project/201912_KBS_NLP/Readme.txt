=========== Abstract ===========
* 이 폴더는 2019.12 부터 2020.01 까지 수행 한, 
"KBS 시사직격 - 정치 여론 빅데이터 분석" 에 대한 
정리 폴더 입니다. 

* 폴더 설명 : 
1. Driver : 파이썬에서 웹 크롤링을 도와주는 패키지 'selenium'을 사용하기위해
필요한 크롬 웹 브라우저 버전 79.에 대한 driver가 들어있습니다. 
2. 그림자료 : 리플에 간단한 빈도 분석을 마치고, 시각화 한 그림들이 들어있습니다. 
3. 실행코드 : 파이썬- 주피터 노트북에서 열 수 있는 실행코드들입니다. 
4. 조선_전체 : 분석 범위가 된 기간과, 키워드들에 대해 '조선일보'에서 스크랩한 
리플과 간단한 기사 데이터들이 들어있습니다. 
5. 한국_전체 : 분석 범위가 된 기간과, 키워드들에 대해 '한국일보'에서 스크랩한 
리플과 간단한 기사 데이터들이 들어있습니다. 

* : 파이썬, 아나콘다, 주피터 노트북이 설치가 되어있지 않은 경우, 
코드만 확인하시고자 한다면, 
'실행코드'폴더에 '.html'로 된 파일로 열람하실 수 있습니다. 

=========== Project Detail ===========

KBS 시사직격 - 정치 여론 빅데이터 분석 : 
수행기간 : ~ 2020.01.08

목적 : 다가오는 21대 총선에 앞서, 국민들은 '20대 국회'를, '공천'을 어떻게
생각하는지 알아보기위해, 대한민국 대표 언론사들의 정치기사에 달린 
댓글들을 수집하고 분석하여 여론을 들여다보고자 한다. 

방법 : 대한민국 언론사 중 세 곳 (조선일보 / 한국일보 / 한겨레)에 
, 키워드 '20대 국회', '공천' 에 관한 정치 기사를 찾고, 이 기사들에 달린
 리플들에 대한 자연어 분석을 수행한다. 

세부 과정 :

1.) 웹 크롤링  
    1.1 :  '다음 뉴스'에 접속하여 /키워드/언론사/기간을 입력하고
해당하는 기사의 url을 모두 긁어온다. 

    1.2 : 각 언론사마다 별도의 '리플 스크래퍼'를 만들어서 해당기사의 
리플 전체를 크롤링 한다. 

    1.3 : 주간 단위로 쪼개져 있는 csv파일을 기간별/ 키워드별/ 언론사별/ 
기준을 통해 소수의 csv파일로 merge한다. 

2.)  자연어 분석
    2.1 : 수집한 리플을 모아 기본 자연어 처리(1. 형태소 필터링 2. 클렌징 등)를
거쳐 키워드별 / 월별 최빈 단어 테이블을 xlsx로 저장한다. 
    2.2 : 월별로 쪼개진 xlsx파일을 merge시켜 몇 개의 파일로 간추린다.
    2.3 : 키워드별 전체 기간에 대한 빈도 테이블을 사용해 시각화를 수행한다.
    
3.) 리플 감성 분석 (* After analysis) *** 감성분석 방법론을 수행하지는 못함. 
    3.1 : 전체 리플 중, 랜덤 샘플을 통해 추려낸 몇 개의 리플에 긍정/부정
labeling을 수행하고, 긍정/부정의 비율을 계산한다. 
